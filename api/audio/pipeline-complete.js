// üéØ PIPELINE COMPLETO FASES 5.1 - 5.4
// Integra√ß√£o completa: Decodifica√ß√£o ‚Üí Segmenta√ß√£o ‚Üí Core Metrics ‚Üí JSON Output + Scoring

import decodeAudioFile from "./audio-decoder.js";              // Fase 5.1
import { segmentAudioTemporal } from "./temporal-segmentation.js"; // Fase 5.2  
import { calculateCoreMetrics } from "./core-metrics.js";      // Fase 5.3
import { generateJSONOutput } from "./json-output.js";         // Fase 5.4

console.log('üéµ Pipeline Completo (Fases 5.1-5.4) carregado - Node.js Backend');

/**
 * Executa pipeline completo de an√°lise de √°udio
 * @param {Buffer|Uint8Array} audioBuffer - Buffer do arquivo de √°udio
 * @param {string} fileName - Nome do arquivo
 * @param {Object} options - Op√ß√µes de processamento
 * @returns {Object} JSON final com m√©tricas e score
 */
export async function processAudioComplete(audioBuffer, fileName, options = {}) {
  const startTime = Date.now();
  
  console.log(`üöÄ Iniciando pipeline completo para: ${fileName}`);
  console.log(`üìä Buffer size: ${audioBuffer.length} bytes`);
  console.log(`üîß Op√ß√µes:`, options);

  try {
    // ‚úÖ FASE 5.1: Decodifica√ß√£o de √Åudio
    console.log('üéµ Fase 5.1: Decodifica√ß√£o...');
    const phaseStartTime = Date.now();
    
    const audioData = await decodeAudioFile(audioBuffer, fileName);
    const phase1Time = Date.now() - phaseStartTime;
    
    console.log(`‚úÖ Fase 5.1 conclu√≠da em ${phase1Time}ms`);
    console.log(`üìä Audio decodificado: ${audioData.sampleRate}Hz, ${audioData.channels}ch, ${audioData.duration.toFixed(2)}s`);

    // ‚úÖ FASE 5.2: Segmenta√ß√£o Temporal
    console.log('‚è±Ô∏è Fase 5.2: Segmenta√ß√£o Temporal...');
    const phase2StartTime = Date.now();
    
    const segmentedData = segmentAudioTemporal(audioData);
    const phase2Time = Date.now() - phase2StartTime;
    
    console.log(`‚úÖ Fase 5.2 conclu√≠da em ${phase2Time}ms`);
    console.log(`üìä FFT frames: ${segmentedData.framesFFT.left.length}, RMS frames: ${segmentedData.framesRMS.left.length}`);

    // ‚úÖ FASE 5.3: Core Metrics
    console.log('üìä Fase 5.3: Core Metrics...');
    const phase3StartTime = Date.now();
    
    const coreMetrics = await calculateCoreMetrics(segmentedData);
    const phase3Time = Date.now() - phase3StartTime;
    
    console.log(`‚úÖ Fase 5.3 conclu√≠da em ${phase3Time}ms`);
    console.log(`üìä LUFS: ${coreMetrics.lufs.integrated.toFixed(1)}`, 
                `True Peak: ${coreMetrics.truePeak.maxDbtp.toFixed(1)}dBTP`,
                `Correla√ß√£o: ${coreMetrics.stereo.correlation.toFixed(3)}`);

    // ‚úÖ FASE 5.4: JSON Output + Scoring
    console.log('üéØ Fase 5.4: JSON Output + Scoring...');
    const phase4StartTime = Date.now();
    
    // Preparar metadados
    const metadata = {
      fileName,
      fileSize: audioBuffer.length,
      processingTime: Date.now() - startTime
    };

    // Refer√™ncia de g√™nero (se fornecida)
    const reference = options.reference || options.genre || null;
    
    const finalJSON = generateJSONOutput(coreMetrics, reference, metadata);
    const phase4Time = Date.now() - phase4StartTime;
    
    console.log(`‚úÖ Fase 5.4 conclu√≠da em ${phase4Time}ms`);
    console.log(`üéØ Score final: ${finalJSON.score}% (${finalJSON.classification})`);

    // ‚úÖ Estat√≠sticas finais
    const totalTime = Date.now() - startTime;
    console.log(`üèÅ Pipeline completo finalizado em ${totalTime}ms`);
    console.log(`‚ö° Breakdown: Decodifica√ß√£o=${phase1Time}ms, Segmenta√ß√£o=${phase2Time}ms, Core=${phase3Time}ms, JSON=${phase4Time}ms`);

    // Atualizar tempo no resultado final
    finalJSON.metadata.processingTime = totalTime;
    finalJSON.metadata.phaseBreakdown = {
      phase1_decoding: phase1Time,
      phase2_segmentation: phase2Time, 
      phase3_core_metrics: phase3Time,
      phase4_json_output: phase4Time,
      total: totalTime
    };

    return finalJSON;

  } catch (error) {
    const totalTime = Date.now() - startTime;
    console.error(`‚ùå Pipeline falhou ap√≥s ${totalTime}ms:`, error);

    // Retornar JSON de erro estruturado
    return {
      status: 'error',
      error: {
        message: error.message,
        type: 'pipeline_error',
        phase: identifyFailedPhase(error.message),
        timestamp: new Date().toISOString(),
        processingTime: totalTime
      },
      score: 50,
      classification: 'Erro',
      scoringMethod: 'error_fallback',
      metadata: {
        fileName,
        fileSize: audioBuffer.length,
        sampleRate: 48000,
        channels: 2,
        duration: 0,
        processedAt: new Date().toISOString(),
        engineVersion: '5.1-5.4-error',
        pipelinePhase: 'error'
      },
      technicalData: {},
      warnings: [`Pipeline error: ${error.message}`],
      buildVersion: '5.4.0-pipeline-error',
      frontendCompatible: false
    };
  }
}

/**
 * Identifica em qual fase o pipeline falhou
 */
function identifyFailedPhase(errorMessage) {
  const message = errorMessage.toLowerCase();
  
  if (message.includes('ffmpeg') || message.includes('decode') || message.includes('audio format')) {
    return 'phase_5_1_decoding';
  }
  
  if (message.includes('fft') || message.includes('segment') || message.includes('temporal')) {
    return 'phase_5_2_segmentation';
  }
  
  if (message.includes('lufs') || message.includes('true peak') || message.includes('core metric')) {
    return 'phase_5_3_core_metrics';
  }
  
  if (message.includes('json') || message.includes('scoring') || message.includes('score')) {
    return 'phase_5_4_json_output';
  }
  
  return 'unknown_phase';
}

/**
 * Vers√£o simplificada que apenas calcula o score
 * @param {Buffer|Uint8Array} audioBuffer - Buffer do arquivo
 * @param {string} fileName - Nome do arquivo
 * @param {Object} reference - Refer√™ncia de g√™nero
 * @returns {Object} Apenas score e classifica√ß√£o
 */
export async function calculateAudioScore(audioBuffer, fileName, reference = null) {
  console.log(`üéØ Calculando score para: ${fileName}`);
  
  try {
    const fullResult = await processAudioComplete(audioBuffer, fileName, { reference });
    
    return {
      score: fullResult.score,
      classification: fullResult.classification,
      method: fullResult.scoringMethod,
      processingTime: fullResult.metadata.processingTime,
      fileName: fileName,
      status: 'success'
    };
    
  } catch (error) {
    console.error('‚ùå Erro ao calcular score:', error);
    
    return {
      score: 50,
      classification: 'Erro',
      method: 'error_fallback',
      processingTime: 0,
      fileName: fileName,
      status: 'error',
      error: error.message
    };
  }
}

/**
 * Valida se o pipeline est√° funcionando corretamente
 * @returns {Promise<boolean>} True se pipeline OK
 */
export async function validatePipeline() {
  console.log('üß™ Validando pipeline completo...');
  
  try {
    // Gerar sinal de teste (1kHz, 1 segundo, 48kHz)
    const testAudio = generateTestAudio();
    console.log('üéµ Sinal de teste gerado');
    
    // Processar com pipeline completo
    const result = await processAudioComplete(testAudio, 'test-signal.wav');
    
    // Verifica√ß√µes b√°sicas
    const checks = [
      { name: 'Status success', pass: result.status === 'success' },
      { name: 'Score v√°lido', pass: Number.isFinite(result.score) && result.score >= 0 && result.score <= 100 },
      { name: 'Classifica√ß√£o presente', pass: !!result.classification },
      { name: 'LUFS v√°lido', pass: Number.isFinite(result.technicalData.lufsIntegrated) },
      { name: 'True Peak v√°lido', pass: Number.isFinite(result.technicalData.truePeakDbtp) },
      { name: 'Correla√ß√£o v√°lida', pass: Number.isFinite(result.technicalData.stereoCorrelation) },
      { name: 'JSON serializ√°vel', pass: !!JSON.stringify(result) }
    ];
    
    const failedChecks = checks.filter(check => !check.pass);
    
    if (failedChecks.length === 0) {
      console.log('‚úÖ Pipeline validado com sucesso!');
      console.log(`üéØ Score teste: ${result.score}% (${result.classification})`);
      return true;
    } else {
      console.error('‚ùå Valida√ß√£o falhou:');
      failedChecks.forEach(check => console.error(`  - ${check.name}`));
      return false;
    }
    
  } catch (error) {
    console.error('‚ùå Erro na valida√ß√£o:', error);
    return false;
  }
}

/**
 * Gera √°udio de teste para valida√ß√£o
 */
function generateTestAudio() {
  // Simular WAV de 1 segundo, 48kHz, est√©reo, 1kHz sine wave
  const sampleRate = 48000;
  const duration = 1.0;
  const frequency = 1000;
  const samples = Math.floor(sampleRate * duration);
  
  // Header WAV simplificado (44 bytes)
  const headerSize = 44;
  const dataSize = samples * 4; // 2 channels * 2 bytes per sample
  const fileSize = headerSize + dataSize;
  
  const buffer = new ArrayBuffer(fileSize);
  const view = new DataView(buffer);
  
  // WAV Header
  let offset = 0;
  
  // "RIFF"
  view.setUint32(offset, 0x52494646, false); offset += 4;
  // File size - 8
  view.setUint32(offset, fileSize - 8, true); offset += 4;
  // "WAVE"
  view.setUint32(offset, 0x57415645, false); offset += 4;
  // "fmt "
  view.setUint32(offset, 0x666d7420, false); offset += 4;
  // fmt chunk size
  view.setUint32(offset, 16, true); offset += 4;
  // Audio format (1 = PCM)
  view.setUint16(offset, 1, true); offset += 2;
  // Channels
  view.setUint16(offset, 2, true); offset += 2;
  // Sample rate
  view.setUint32(offset, sampleRate, true); offset += 4;
  // Byte rate
  view.setUint32(offset, sampleRate * 4, true); offset += 4;
  // Block align
  view.setUint16(offset, 4, true); offset += 2;
  // Bits per sample
  view.setUint16(offset, 16, true); offset += 2;
  // "data"
  view.setUint32(offset, 0x64617461, false); offset += 4;
  // Data chunk size
  view.setUint32(offset, dataSize, true); offset += 4;
  
  // Audio data (1kHz sine wave)
  for (let i = 0; i < samples; i++) {
    const t = i / sampleRate;
    const sample = Math.sin(2 * Math.PI * frequency * t) * 0.5; // -6dB
    const intSample = Math.round(sample * 32767);
    
    // Left channel
    view.setInt16(offset, intSample, true); offset += 2;
    // Right channel  
    view.setInt16(offset, intSample, true); offset += 2;
  }
  
  return new Uint8Array(buffer);
}

/**
 * Pipeline completo para uso em API/servidor
 */
export default {
  processAudioComplete,
  calculateAudioScore,
  validatePipeline
};