// work/index.js
import "dotenv/config";                    // ‚úÖ sem .js
import pkg from "pg";
import AWS from "aws-sdk";
import fs from "fs";
import path from "path";
import * as mm from "music-metadata";      // ‚úÖ import correto (se usar depois)
import ffmpeg from "fluent-ffmpeg";        // ok se for usar depois

const { Client } = pkg;

// ---------- Conectar ao Postgres ----------
const client = new Client({
  connectionString: process.env.DATABASE_URL,
  ssl: process.env.PGSSL === "disable" ? false : { rejectUnauthorized: false },
});

await client.connect();
console.log("‚úÖ Worker conectado ao Postgres");

// ---------- Configura√ß√£o Backblaze ----------
const s3 = new AWS.S3({
  endpoint: process.env.B2_ENDPOINT || "https://s3.us-east-005.backblazeb2.com",
  region: "us-east-005",
  accessKeyId: process.env.B2_KEY_ID,
  secretAccessKey: process.env.B2_APP_KEY,
  signatureVersion: "v4",
});

const BUCKET_NAME = process.env.B2_BUCKET_NAME;

// ---------- Fun√ß√£o para baixar arquivo ----------
async function downloadFileFromBucket(key) {
  const localPath = path.join("/tmp", path.basename(key)); // Railway usa /tmp
  await fs.promises.mkdir(path.dirname(localPath), { recursive: true });

  return new Promise((resolve, reject) => {
    const write = fs.createWriteStream(localPath);
    const read = s3.getObject({ Bucket: BUCKET_NAME, Key: key }).createReadStream();

    read.on("error", (err) => {
      console.error("‚ùå Erro no stream de leitura S3:", err);
      reject(err);
    });

    write.on("error", (err) => {
      console.error("‚ùå Erro no stream de escrita local:", err);
      reject(err);
    });

    // ‚úÖ s√≥ resolve quando o arquivo foi gravado
    write.on("finish", () => {
      console.log(`üì• Arquivo baixado: ${localPath}`);
      resolve(localPath);
    });

    read.pipe(write);
  });
}

// ---------- Processar 1 job ----------
async function processJob(job) {
  console.log("üì• Processando job:", job.id);

  try {
    // Atualiza para "processing"
    await client.query(
      "UPDATE jobs SET status = $1, updated_at = NOW() WHERE id = $2",
      ["processing", job.id]
    );

    // Baixar arquivo do bucket
    const localFilePath = await downloadFileFromBucket(job.file_key);
    console.log(`üéµ Arquivo pronto para an√°lise: ${localFilePath}`);

    // (Placeholder) ‚Äî aqui entra sua an√°lise real com mm/ffmpeg
    // const meta = await mm.parseFile(localFilePath);
    // console.log("üé∂ Metadata:", meta.format);

    const result = {
      ok: true,
      file: job.file_key,
      mode: job.mode,
      analyzedAt: new Date().toISOString(),
      // example: format: meta?.format ?? null,
    };

    // Salva resultado no banco
    await client.query(
      "UPDATE jobs SET status = $1, result = $2, completed_at = NOW(), updated_at = NOW() WHERE id = $3",
      ["done", JSON.stringify(result), job.id]
    );

    console.log(`‚úÖ Job ${job.id} conclu√≠do`);
  } catch (err) {
    console.error("‚ùå Erro no job:", err);
    await client.query(
      "UPDATE jobs SET status = $1, error = $2, updated_at = NOW() WHERE id = $3",
      ["failed", err?.message ?? String(err), job.id]
    );
  }
}

// ---------- Loop para buscar jobs (com lock) ----------
let isRunning = false;

async function processJobs() {
  if (isRunning) return;
  isRunning = true;

  try {
    console.log("üîÑ Worker verificando jobs...");
    const res = await client.query(
      "SELECT * FROM jobs WHERE status = 'queued' ORDER BY created_at ASC LIMIT 1"
    );

    if (res.rows.length > 0) {
      await processJob(res.rows[0]);
    } else {
      console.log("üì≠ Nenhum job novo.");
    }
  } catch (e) {
    console.error("‚ùå Erro no loop de jobs:", e);
  } finally {
    isRunning = false;
  }
}

// ---------- Executa a cada 5s ----------
setInterval(processJobs, 5000);
// dispara uma vez logo no start
processJobs();
