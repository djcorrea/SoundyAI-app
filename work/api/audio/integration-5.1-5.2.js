/**
 * Exemplo de Integra√ß√£o - Fases 5.1 + 5.2
 * 
 * Demonstra como integrar a decodifica√ß√£o (5.1) com a segmenta√ß√£o temporal (5.2)
 * Pipeline completo: Arquivo ‚Üí Float32Array ‚Üí Frames segmentados
 */

import { decodeAudioFile } from './audio-decoder.js';
import { segmentAudioTemporal, calculateFrameTiming } from './temporal-segmentation.js';
import { generateTestWav } from './test-audio-decoder.js';

/**
 * Pipeline completo: Decodifica√ß√£o + Segmenta√ß√£o
 * 
 * @param {Buffer} audioFileBuffer - Buffer do arquivo de √°udio
 * @param {string} filename - Nome do arquivo
 * @returns {Promise<Object>} - Dados segmentados prontos para an√°lise
 */
export async function processAudioComplete(audioFileBuffer, filename) {
  const startTime = Date.now();
  
  try {
    console.log(`[PIPELINE] Iniciando processamento completo: ${filename}`);
    
    // FASE 5.1: Decodifica√ß√£o
    console.log(`[PIPELINE] Fase 5.1: Decodifica√ß√£o...`);
    const audioData = await decodeAudioFile(audioFileBuffer, filename);
    
    console.log(`[PIPELINE] Fase 5.1 conclu√≠da:`, {
      sampleRate: audioData.sampleRate,
      channels: audioData.numberOfChannels,
      duration: audioData.duration,
      samples: audioData.length
    });
    
    // FASE 5.2: Segmenta√ß√£o Temporal
    console.log(`[PIPELINE] Fase 5.2: Segmenta√ß√£o temporal...`);
    const segmentedData = segmentAudioTemporal(audioData);
    
    console.log(`[PIPELINE] Fase 5.2 conclu√≠da:`, {
      fftFrames: segmentedData.framesFFT.count,
      rmsFrames: segmentedData.framesRMS.count,
      fftFrameSize: segmentedData.framesFFT.frameSize,
      rmsFrameSize: segmentedData.framesRMS.frameSize
    });
    
    const totalTime = Date.now() - startTime;
    console.log(`[PIPELINE] Pipeline completo executado em ${totalTime}ms`);
    
    // Estrutura de retorno com dados das duas fases
    return {
      // Dados originais (Fase 5.1)
      original: {
        filename: filename,
        sampleRate: audioData.sampleRate,
        numberOfChannels: audioData.numberOfChannels,
        length: audioData.length,
        duration: audioData.duration,
        originalFormat: audioData._metadata.originalFormat,
        decodingTime: audioData._metadata.processingTime
      },
      
      // Dados segmentados (Fase 5.2)
      segmented: segmentedData,
      
      // Metadados do pipeline
      pipeline: {
        phase: '5.1+5.2-complete',
        totalProcessingTime: totalTime,
        processedAt: new Date().toISOString(),
        readyForPhases: ['5.3-metrics', '5.4-scoring']
      }
    };
    
  } catch (error) {
    const totalTime = Date.now() - startTime;
    console.error(`[PIPELINE] Erro ap√≥s ${totalTime}ms:`, error);
    
    // Re-throw com contexto do pipeline
    const enhancedError = new Error(`PIPELINE_FAILED: ${error.message}`);
    enhancedError.originalError = error;
    enhancedError.phase = error.phase || 'unknown';
    enhancedError.totalProcessingTime = totalTime;
    
    throw enhancedError;
  }
}

/**
 * Exemplo pr√°tico: Processar arquivo WAV sint√©tico
 */
export async function demonstrateFullPipeline() {
  console.log('üéµ DEMONSTRA√á√ÉO DO PIPELINE COMPLETO (5.1 + 5.2)');
  console.log('‚ïê'.repeat(60));
  
  try {
    // Gerar WAV de teste (3 segundos, est√©reo, 440Hz)
    console.log('1Ô∏è‚É£ Gerando arquivo WAV de teste...');
    const testWav = generateTestWav(3.0, 440);
    console.log(`   WAV gerado: ${testWav.length} bytes, 3.0s, est√©reo, 440Hz`);
    
    // Processar atrav√©s do pipeline completo
    console.log('\n2Ô∏è‚É£ Executando pipeline completo...');
    const result = await processAudioComplete(testWav, 'demo-pipeline.wav');
    
    // Analisar resultados
    console.log('\n3Ô∏è‚É£ Analisando resultados...');
    
    console.log('\nüìä RESULTADOS DA FASE 5.1 (Decodifica√ß√£o):');
    console.log(`   ‚úÖ Sample Rate: ${result.original.sampleRate} Hz`);
    console.log(`   ‚úÖ Canais: ${result.original.numberOfChannels}`);
    console.log(`   ‚úÖ Dura√ß√£o: ${result.original.duration.toFixed(3)}s`);
    console.log(`   ‚úÖ Samples: ${result.original.length} por canal`);
    console.log(`   ‚úÖ Tempo decodifica√ß√£o: ${result.original.decodingTime}ms`);
    
    console.log('\nüìä RESULTADOS DA FASE 5.2 (Segmenta√ß√£o):');
    console.log(`   ‚úÖ Frames FFT: ${result.segmented.framesFFT.count} (${result.segmented.framesFFT.frameSize} samples cada)`);
    console.log(`   ‚úÖ Frames RMS: ${result.segmented.framesRMS.count} (${result.segmented.framesRMS.frameSize} samples cada)`);
    console.log(`   ‚úÖ FFT Hop: ${result.segmented.framesFFT.hopSize} samples (${result.segmented.framesFFT.windowType} window)`);
    console.log(`   ‚úÖ RMS Hop: ${result.segmented.framesRMS.hopSize} samples (${result.segmented.framesRMS.hopDurationMs}ms)`);
    console.log(`   ‚úÖ Tempo segmenta√ß√£o: ${result.segmented._metadata.processingTime}ms`);
    
    console.log('\nüìä PIPELINE GERAL:');
    console.log(`   ‚úÖ Tempo total: ${result.pipeline.totalProcessingTime}ms`);
    console.log(`   ‚úÖ Fases completas: 5.1 + 5.2`);
    console.log(`   ‚úÖ Pr√≥ximas fases: ${result.pipeline.readyForPhases.join(', ')}`);
    
    // Valida√ß√µes espec√≠ficas
    console.log('\n4Ô∏è‚É£ Valida√ß√µes espec√≠ficas...');
    
    // Validar c√°lculo de frames para 3 segundos (144000 samples)
    const expectedFFT = Math.floor((144000 - 4096) / 1024) + 1; // 137 frames
    const expectedRMS = Math.floor(144000 / 4800); // 30 frames
    
    if (result.segmented.framesFFT.count !== expectedFFT) {
      throw new Error(`FFT frames incorreto: ${result.segmented.framesFFT.count} !== ${expectedFFT}`);
    }
    
    if (result.segmented.framesRMS.count !== expectedRMS) {
      throw new Error(`RMS frames incorreto: ${result.segmented.framesRMS.count} !== ${expectedRMS}`);
    }
    
    console.log(`   ‚úÖ FFT frames: ${result.segmented.framesFFT.count} (esperado: ${expectedFFT})`);
    console.log(`   ‚úÖ RMS frames: ${result.segmented.framesRMS.count} (esperado: ${expectedRMS})`);
    
    // Verificar que os frames t√™m os tamanhos corretos
    const firstFFTFrame = result.segmented.framesFFT.left[0];
    const firstRMSFrame = result.segmented.framesRMS.left[0];
    
    if (firstFFTFrame.length !== 4096) {
      throw new Error(`FFT frame size incorreto: ${firstFFTFrame.length} !== 4096`);
    }
    
    if (firstRMSFrame.length !== 14400) {
      throw new Error(`RMS frame size incorreto: ${firstRMSFrame.length} !== 14400`);
    }
    
    console.log(`   ‚úÖ FFT frame size: ${firstFFTFrame.length} samples`);
    console.log(`   ‚úÖ RMS frame size: ${firstRMSFrame.length} samples`);
    
    // Verificar janela Hann aplicada
    if (Math.abs(firstFFTFrame[0]) > 0.01 || Math.abs(firstFFTFrame[4095]) > 0.01) {
      throw new Error('Janela Hann n√£o foi aplicada corretamente');
    }
    
    console.log(`   ‚úÖ Janela Hann aplicada (bordas ~0)`);
    
    console.log('\nüéâ DEMONSTRA√á√ÉO CONCLU√çDA COM SUCESSO!');
    console.log('Pipeline 5.1 + 5.2 est√° funcionando perfeitamente.');
    
    return {
      success: true,
      processingTime: result.pipeline.totalProcessingTime,
      fftFrames: result.segmented.framesFFT.count,
      rmsFrames: result.segmented.framesRMS.count,
      validations: 'all_passed'
    };
    
  } catch (error) {
    console.error('\n‚ùå ERRO NA DEMONSTRA√á√ÉO:', error.message);
    console.error('Stack:', error.stack);
    
    return {
      success: false,
      error: error.message,
      phase: error.phase || 'unknown'
    };
  }
}

/**
 * Utilit√°rio: Analisar timing de frames para debug
 */
export function analyzeFrameTiming(segmentedData) {
  const fftTiming = [];
  const rmsTiming = [];
  
  // Calcular timestamps dos frames FFT
  for (let i = 0; i < segmentedData.framesFFT.count; i++) {
    const timestamp = (i * segmentedData.framesFFT.hopSize) / segmentedData.sampleRate;
    fftTiming.push({
      frameIndex: i,
      startTime: timestamp.toFixed(6),
      startSample: i * segmentedData.framesFFT.hopSize
    });
  }
  
  // Calcular timestamps dos frames RMS
  for (let i = 0; i < segmentedData.framesRMS.count; i++) {
    const timestamp = (i * segmentedData.framesRMS.hopSize) / segmentedData.sampleRate;
    rmsTiming.push({
      frameIndex: i,
      startTime: timestamp.toFixed(6),
      startSample: i * segmentedData.framesRMS.hopSize
    });
  }
  
  return {
    audioDuration: segmentedData.duration,
    fft: {
      frameCount: segmentedData.framesFFT.count,
      timing: fftTiming.slice(0, 10), // Primeiros 10 para debug
      lastFrame: fftTiming[fftTiming.length - 1]
    },
    rms: {
      frameCount: segmentedData.framesRMS.count,
      timing: rmsTiming.slice(0, 10), // Primeiros 10 para debug
      lastFrame: rmsTiming[rmsTiming.length - 1]
    }
  };
}

// Executar demonstra√ß√£o se chamado diretamente
if (import.meta.url === `file://${process.argv[1]}`) {
  demonstrateFullPipeline()
    .then((result) => {
      process.exit(result.success ? 0 : 1);
    })
    .catch((error) => {
      console.error('‚ùå ERRO CR√çTICO:', error);
      process.exit(1);
    });
}
