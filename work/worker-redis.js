// worker-redis.js - WORKER REDIS EXCLUSIVO PARA RAILWAY
// üöÄ Conex√£o Redis robusta com REDIS_URL e reconex√£o autom√°tica

import "dotenv/config";
import BullMQ from 'bullmq';
import Redis from 'ioredis';
import pool from './db.js';
import AWS from "aws-sdk";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import express from 'express';

console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üöÄ INICIANDO Worker Redis Exclusivo...`);
console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üìã PID: ${process.pid}`);
console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üåç ENV: ${process.env.NODE_ENV || 'development'}`);
console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üèóÔ∏è Platform: ${process.platform}`);
console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üß† Memory: ${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB`);

if (process.env.NODE_ENV === 'production') {
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üöÄ MODO PRODU√á√ÉO ATIVADO`);
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üîß Redis: ${process.env.REDIS_URL ? 'CONFIGURADO' : 'N√ÉO CONFIGURADO'}`);
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üóÉÔ∏è Postgres: ${process.env.DATABASE_URL ? 'CONFIGURADO' : 'N√ÉO CONFIGURADO'}`);
}

// ---------- CONFIGURA√á√ÉO REDIS ROBUSTA PARA RAILWAY ----------
const { Queue, Worker } = BullMQ;

if (!process.env.REDIS_URL) {
  console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> üö® ERRO CR√çTICO: REDIS_URL n√£o configurado!`);
  process.exit(1);
}

console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üîó Conectando ao Redis...`);

// üîó Conex√£o Redis otimizada para Railway - USA APENAS REDIS_URL
const redisConnection = new Redis(process.env.REDIS_URL, {
  maxRetriesPerRequest: null,  // ‚úÖ Obrigat√≥rio para BullMQ
  lazyConnect: true,
  connectTimeout: 45000,
  commandTimeout: 15000,
  keepAlive: 120000,
  enableReadyCheck: false,
  enableAutoPipelining: true,
  family: 4,
  
  // üîÑ RETRY STRATEGY ROBUSTO - Reconex√£o autom√°tica
  retryStrategy: (times) => {
    const delay = Math.min(times * 2000, 30000); // M√°ximo 30s
    console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üîÑ Tentando reconectar... (tentativa ${times}, delay: ${delay}ms)`);
    return delay;
  },
  
  retryDelayOnFailover: 2000,
});

// üî• Event Listeners CORRETOS para conex√£o Redis
redisConnection.on('connect', () => {
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚úÖ Conectado ao Redis`);
});

redisConnection.on('ready', () => {
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚úÖ Redis pronto para uso`);
});

redisConnection.on('error', (err) => {
  console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> üö® Erro ao conectar ao Redis: ${err.message}`);
});

redisConnection.on('reconnecting', (delay) => {
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üîÑ Tentando reconectar... (delay: ${delay}ms)`);
});

redisConnection.on('end', () => {
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üîå Conex√£o Redis encerrada`);
});

redisConnection.on('close', () => {
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üö™ Conex√£o Redis fechada`);
});

// üìã Criar fila BullMQ
const audioQueue = new Queue('audio-analyzer', { 
  connection: redisConnection,
  defaultJobOptions: {
    removeOnComplete: 5,
    removeOnFail: 10,
    attempts: 2,
    backoff: {
      type: 'fixed',
      delay: 10000
    },
    ttl: 300000,
    delay: 0
  }
});

console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üìã Fila 'audio-analyzer' criada`);

// ---------- Global Error Handlers ----------
process.on('uncaughtException', (err) => {
  console.error(`[FATAL][${new Date().toISOString()}] -> üö® UNCAUGHT EXCEPTION: ${err.message}`);
  console.error(`[FATAL][${new Date().toISOString()}] -> Stack trace:`, err.stack);
  
  try {
    console.log(`[FATAL][${new Date().toISOString()}] -> üîå Tentando fechar conex√µes...`);
    process.exit(1);
  } catch (closeErr) {
    console.error(`[FATAL][${new Date().toISOString()}] -> ‚ùå Erro ao fechar conex√µes:`, closeErr);
    process.exit(1);
  }
});

process.on('unhandledRejection', (reason, promise) => {
  console.error(`[FATAL][${new Date().toISOString()}] -> üö® UNHANDLED REJECTION: ${reason}`);
  console.error(`[FATAL][${new Date().toISOString()}] -> Promise:`, promise);
  console.error(`[FATAL][${new Date().toISOString()}] -> Stack trace:`, reason.stack);
});

process.on('warning', (warning) => {
  console.warn(`[FATAL][${new Date().toISOString()}] -> ‚ö†Ô∏è WARNING: ${warning.name}: ${warning.message}`);
});

// ---------- Importar pipeline completo ----------
let processAudioComplete = null;

try {
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üì¶ Carregando pipeline completo...`);
  const imported = await import("./api/audio/pipeline-complete.js");
  processAudioComplete = imported.processAudioComplete;
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚úÖ Pipeline completo carregado com sucesso!`);
} catch (err) {
  console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚ùå CR√çTICO: Falha ao carregar pipeline:`, err.message);
  console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> Stack trace:`, err.stack);
  process.exit(1);
}

// ---------- Resolver __dirname ----------
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// ---------- Verificar conex√£o Postgres via Singleton ----------
let pgConnected = false;
try {
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üóÉÔ∏è Testando conex√£o PostgreSQL...`);
  const testResult = await pool.query('SELECT NOW()');
  pgConnected = true;
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚úÖ Conectado ao Postgres via Singleton Pool`);
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üìä Teste de conex√£o: ${testResult.rows[0].now}`);
} catch (err) {
  console.warn(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚ö†Ô∏è Postgres n√£o dispon√≠vel: ${err.message}`);
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üß™ Continuando em modo mock sem Postgres`);
}

// ---------- Configura√ß√£o Backblaze ----------
console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üîç Debug B2 Config:`);
console.log(`[WORKER-REDIS][${new Date().toISOString()}] ->    B2_KEY_ID: ${process.env.B2_KEY_ID}`);
console.log(`[WORKER-REDIS][${new Date().toISOString()}] ->    B2_APP_KEY: ${process.env.B2_APP_KEY?.substring(0,10)}...`);
console.log(`[WORKER-REDIS][${new Date().toISOString()}] ->    B2_BUCKET_NAME: ${process.env.B2_BUCKET_NAME}`);
console.log(`[WORKER-REDIS][${new Date().toISOString()}] ->    B2_ENDPOINT: ${process.env.B2_ENDPOINT}`);

const s3 = new AWS.S3({
  endpoint: process.env.B2_ENDPOINT || "https://s3.us-east-005.backblazeb2.com",
  region: "us-east-005",
  accessKeyId: process.env.B2_KEY_ID,
  secretAccessKey: process.env.B2_APP_KEY,
  signatureVersion: "v4",
});
const BUCKET_NAME = process.env.B2_BUCKET_NAME;

// ---------- Baixar arquivo do bucket ----------
async function downloadFileFromBucket(key) {
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üîç Tentando baixar arquivo: ${key}`);
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üìÅ Bucket: ${BUCKET_NAME}`);
  
  const tempDir = process.env.NODE_ENV === 'production' ? '/tmp' : path.join(__dirname, 'temp');
  await fs.promises.mkdir(tempDir, { recursive: true });
  
  const localPath = path.join(tempDir, `${Date.now()}_${path.basename(key)}`);
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üíæ Caminho local: ${localPath}`);

  return new Promise((resolve, reject) => {
    const write = fs.createWriteStream(localPath);
    const read = s3.getObject({ Bucket: BUCKET_NAME, Key: key }).createReadStream();

    console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚è∞ Iniciando download com timeout de 2 minutos...`);

    const timeout = setTimeout(() => {
      console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚è∞ TIMEOUT: Download excedeu 2 minutos para: ${key}`);
      write.destroy();
      read.destroy();
      reject(new Error(`Download timeout ap√≥s 2 minutos para: ${key}`));
    }, 120000);

    read.on("error", (err) => {
      clearTimeout(timeout);
      console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚ùå Erro no stream de leitura para ${key}:`, err.message);
      if (err.code === 'NoSuchKey') {
        console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> üö® ARQUIVO N√ÉO ENCONTRADO: ${key}`);
        console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> üìÅ Verifique se o arquivo existe no bucket: ${BUCKET_NAME}`);
      }
      console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> üìã Erro code: ${err.code}, statusCode: ${err.statusCode}`);
      reject(new Error(`Arquivo n√£o encontrado no Backblaze: ${key}`));
    });
    write.on("error", (err) => {
      clearTimeout(timeout);
      console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚ùå Erro no stream de escrita para ${key}:`, err.message);
      reject(err);
    });
    write.on("finish", () => {
      clearTimeout(timeout);
      console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚úÖ Download conclu√≠do para ${key}`);
      console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üìè Arquivo salvo em: ${localPath}`);
      resolve(localPath);
    });

    read.pipe(write);
  });
}

// ---------- An√°lise REAL via pipeline ----------
async function analyzeAudioWithPipeline(localFilePath, jobData) {
  const filename = path.basename(localFilePath);
  
  try {
    const fileBuffer = await fs.promises.readFile(localFilePath);
    console.log(`üìä [WORKER-REDIS] Arquivo lido: ${fileBuffer.length} bytes`);

    const t0 = Date.now();
    
    const pipelinePromise = processAudioComplete(fileBuffer, filename, {
      jobId: jobData.jobId,
      reference: jobData?.reference || null
    });
    const timeoutPromise = new Promise((_, reject) => {
      setTimeout(() => {
        reject(new Error(`Pipeline timeout ap√≥s 3 minutos para: ${filename}`));
      }, 180000);
    });

    console.log(`‚ö° [WORKER-REDIS] Iniciando processamento de ${filename}...`);
    const finalJSON = await Promise.race([pipelinePromise, timeoutPromise]);
    const totalMs = Date.now() - t0;
    
    console.log(`‚úÖ [WORKER-REDIS] Pipeline conclu√≠do em ${totalMs}ms`);

    finalJSON.performance = {
      ...(finalJSON.performance || {}),
      workerTotalTimeMs: totalMs,
      workerTimestamp: new Date().toISOString(),
      backendPhase: "5.1-5.4-redis",
      workerId: process.pid
    };

    finalJSON._worker = { 
      source: "pipeline_complete", 
      redis: true,
      pid: process.pid
    };

    return finalJSON;
    
  } catch (error) {
    console.error(`‚ùå [WORKER-REDIS] Erro cr√≠tico no pipeline para ${filename}:`, error.message);
    
    return {
      status: 'error',
      error: {
        message: error.message,
        type: 'worker_pipeline_error',
        phase: 'worker_redis_processing',
        timestamp: new Date().toISOString()
      },
      score: 0,
      classification: 'Erro Cr√≠tico',
      scoringMethod: 'worker_redis_error_fallback',
      metadata: {
        fileName: filename,
        fileSize: 0,
        sampleRate: 48000,
        channels: 2,
        duration: 0,
        processedAt: new Date().toISOString(),
        engineVersion: 'worker-redis-error',
        pipelinePhase: 'error'
      },
      technicalData: {},
      warnings: [`Worker Redis error: ${error.message}`],
      buildVersion: 'worker-redis-error',
      frontendCompatible: false,
      _worker: { 
        source: "pipeline_error", 
        error: true, 
        redis: true,
        pid: process.pid
      }
    };
  }
}

// ---------- Atualizar status do job no Postgres ----------
async function updateJobStatus(jobId, status, data = null, error = null) {
  if (!pgConnected) {
    console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üß™ Mock update: ${jobId} -> ${status} (Postgres n√£o dispon√≠vel)`);
    return;
  }

  try {
    console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üíæ Atualizando status no PostgreSQL: ${jobId} -> ${status}`);
    
    if (status === 'processing') {
      const result = await pool.query(
        "UPDATE jobs SET status = $1, updated_at = NOW() WHERE id = $2",
        [status, jobId]
      );
      console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚úÖ Status 'processing' atualizado (${result.rowCount} rows affected)`);
    } else if (status === 'done') {
      const result = await pool.query(
        "UPDATE jobs SET status = $1, result = $2::jsonb, completed_at = NOW(), updated_at = NOW() WHERE id = $3",
        [status, JSON.stringify(data), jobId]
      );
      console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚úÖ Status 'done' atualizado com resultado (${result.rowCount} rows affected)`);
    } else if (status === 'failed') {
      const result = await pool.query(
        "UPDATE jobs SET status = $1, error = $2, updated_at = NOW() WHERE id = $3",
        [status, error, jobId]
      );
      console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚úÖ Status 'failed' atualizado com erro (${result.rowCount} rows affected)`);
    }
  } catch (err) {
    console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚ùå ERRO ao atualizar status no Postgres: ${err.message}`);
    console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> Stack trace: ${err.stack}`);
  }
}

// ---------- Processor do BullMQ ----------
async function audioProcessor(job) {
  const { jobId, fileKey, mode, fileName } = job.data;
  console.log(`[PROCESS][${new Date().toISOString()}] -> üéµ INICIANDO job ${job.id}`, {
    jobId,
    fileKey,
    mode,
    fileName,
    timestamp: new Date(job.timestamp).toISOString(),
    attempts: job.attemptsMade + 1
  });

  let localFilePath = null;

  try {
    console.log(`[PROCESS][${new Date().toISOString()}] -> üìù Atualizando status para processing no PostgreSQL...`);
    await updateJobStatus(jobId, 'processing');

    console.log(`[PROCESS][${new Date().toISOString()}] -> ‚¨áÔ∏è Iniciando download do arquivo: ${fileKey}`);
    const downloadStartTime = Date.now();
    localFilePath = await downloadFileFromBucket(fileKey);
    const downloadTime = Date.now() - downloadStartTime;
    console.log(`[PROCESS][${new Date().toISOString()}] -> üéµ Arquivo baixado em ${downloadTime}ms: ${localFilePath}`);

    console.log(`[PROCESS][${new Date().toISOString()}] -> üîç Validando arquivo antes do pipeline...`);
    const stats = await fs.promises.stat(localFilePath);
    const fileSizeMB = stats.size / (1024 * 1024);
    
    console.log(`[PROCESS][${new Date().toISOString()}] -> üìè Tamanho do arquivo: ${stats.size} bytes (${fileSizeMB.toFixed(2)} MB)`);
    
    if (stats.size < 1000) {
      throw new Error(`File too small: ${stats.size} bytes (minimum 1KB required)`);
    }
    
    if (fileSizeMB > 100) {
      throw new Error(`File too large: ${fileSizeMB.toFixed(2)} MB (maximum 100MB allowed)`);
    }
    
    console.log(`[PROCESS][${new Date().toISOString()}] -> ‚úÖ Arquivo validado (${fileSizeMB.toFixed(2)} MB)`);

    console.log(`[PROCESS][${new Date().toISOString()}] -> üöÄ Iniciando pipeline completo...`);
    const pipelineStartTime = Date.now();
    const analysisResult = await analyzeAudioWithPipeline(localFilePath, job.data);
    const pipelineTime = Date.now() - pipelineStartTime;
    console.log(`[PROCESS][${new Date().toISOString()}] -> ‚ö° Pipeline conclu√≠do em ${pipelineTime}ms`);

    const result = {
      ok: true,
      file: fileKey,
      mode: mode,
      analyzedAt: new Date().toISOString(),
      workerId: process.pid,
      redis: true,
      timing: {
        downloadMs: downloadTime,
        pipelineMs: pipelineTime,
        totalMs: Date.now() - job.timestamp
      },
      ...analysisResult,
    };

    console.log(`[PROCESS][${new Date().toISOString()}] -> üíæ Salvando resultado no banco...`);
    await updateJobStatus(jobId, 'done', result);

    console.log(`[PROCESS][${new Date().toISOString()}] -> ‚úÖ Job ${job.id} finalizado com sucesso | JobID: ${jobId} | Tempo total: ${Date.now() - job.timestamp}ms`);
    return result;

  } catch (error) {
    console.error(`[PROCESS][${new Date().toISOString()}] -> ‚ùå ERRO no job ${job.id}:`, {
      jobId,
      fileKey,
      error: error.message,
      stack: error.stack,
      duration: Date.now() - job.timestamp
    });
    
    console.log(`[PROCESS][${new Date().toISOString()}] -> üíî Marcando job como failed no banco...`);
    await updateJobStatus(jobId, 'failed', null, error.message);
    
    throw error;
  } finally {
    if (localFilePath) {
      try {
        await fs.promises.unlink(localFilePath);
        console.log(`[PROCESS][${new Date().toISOString()}] -> üóëÔ∏è Arquivo tempor√°rio removido: ${path.basename(localFilePath)}`);
      } catch (e) {
        console.warn(`[PROCESS][${new Date().toISOString()}] -> ‚ö†Ô∏è N√£o foi poss√≠vel remover arquivo tempor√°rio: ${e?.message}`);
      }
    }
  }
}

// ---------- Criar Worker BullMQ com configura√ß√£o robusta ----------
const concurrency = Number(process.env.WORKER_CONCURRENCY) || 5;
console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üè≠ Criando Worker BullMQ`);
console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚öôÔ∏è Concorr√™ncia: ${concurrency}`);

const worker = new Worker('audio-analyzer', audioProcessor, { 
  connection: redisConnection, 
  concurrency,
  settings: {
    stalledInterval: 120000,
    maxStalledCount: 2,
    lockDuration: 180000,
    keepAlive: 60000,
    batchSize: 1,
    delayedDebounce: 10000,
  }
});

console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üéØ Worker criado para fila: 'audio-analyzer'`);
console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üìã PID: ${process.pid}`);

// ---------- Event Listeners do Worker ----------
worker.on('ready', () => {
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üü¢ WORKER PRONTO! PID: ${process.pid}, Concorr√™ncia: ${concurrency}`);
});

// üî• EVENTOS EXATOS CONFORME SOLICITADO
worker.on('waiting', (jobId) => console.log('[EVENT] üü° Job WAITING:', jobId));

worker.on('active', (job) => {
  console.log('[EVENT] üîµ Job ACTIVE:', job.id);
  const { jobId, fileKey } = job.data;
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üéØ PROCESSANDO: ${job.id} | JobID: ${jobId?.substring(0,8)} | File: ${fileKey?.split('/').pop()}`);
});

worker.on('completed', (job, result) => {
  console.log('[EVENT] ‚úÖ Job COMPLETED:', job.id);
  const { jobId, fileKey } = job.data;
  const duration = Date.now() - job.timestamp;
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üéâ CONCLU√çDO: ${job.id} | JobID: ${jobId?.substring(0,8)} | Tempo: ${duration}ms | File: ${fileKey?.split('/').pop()}`);
});

worker.on('failed', (job, err) => {
  console.error('[EVENT] üî¥ Job FAILED:', job.id, err);
  const { jobId, fileKey } = job.data;
  console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> üí• FALHADO: ${job.id} | JobID: ${jobId?.substring(0,8)} | File: ${fileKey?.split('/').pop()} | Erro: ${err.message}`);
});

worker.on('error', (err) => {
  console.error('[EVENT] üö® Worker Error:', err);
  console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> üö® ERRO NO WORKER: ${err.message}`);
  console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> Stack trace:`, err.stack);
});

worker.on('stalled', (job) => {
  const { jobId, fileKey } = job.data;
  console.warn(`[WORKER-REDIS][${new Date().toISOString()}] -> üêå JOB TRAVADO: ${job.id} | JobID: ${jobId?.substring(0,8)} | File: ${fileKey?.split('/').pop()}`);
});

worker.on('progress', (job, progress) => {
  const { jobId } = job.data;
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üìà PROGRESSO: ${job.id} | JobID: ${jobId?.substring(0,8)} | ${progress}%`);
});

// ---------- Monitoramento de performance ----------
const getQueueStats = async () => {
  try {
    const [waitingCount, activeCount, completedCount, failedCount] = await Promise.all([
      audioQueue.getWaitingCount(),
      audioQueue.getActiveCount(),
      audioQueue.getCompletedCount(),
      audioQueue.getFailedCount()
    ]);

    return {
      waiting: waitingCount,
      active: activeCount,
      completed: completedCount,
      failed: failedCount,
      total: waitingCount + activeCount + completedCount + failedCount
    };
  } catch (error) {
    console.error('‚ùå [WORKER-REDIS] Erro ao obter estat√≠sticas:', error);
    return { error: error.message };
  }
};

setInterval(async () => {
  try {
    const stats = await getQueueStats();
    console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üìä FILA: ${stats.waiting} aguardando | ${stats.active} ativas | ${stats.completed} completas | ${stats.failed} falhadas | PID: ${process.pid}`);
  } catch (err) {
    console.warn(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚ö†Ô∏è Erro ao obter stats da fila: ${err.message}`);
  }
}, 180000);

// ---------- Recovery de jobs √≥rf√£os ----------
async function recoverOrphanedJobs() {
  if (!pgConnected) {
    console.log(`üß™ [WORKER-REDIS] Postgres n√£o dispon√≠vel - pulando recovery`);
    return;
  }

  try {
    console.log("üîÑ [WORKER-REDIS] Verificando jobs √≥rf√£os...");
    
    const problematicJobs = await pool.query(`
      SELECT file_key, COUNT(*) as failure_count, 
             ARRAY_AGG(id ORDER BY created_at DESC) as job_ids
      FROM jobs 
      WHERE error LIKE '%Recovered from orphaned state%' 
      OR error LIKE '%Pipeline timeout%'
      OR error LIKE '%FFmpeg%'
      OR error LIKE '%Memory%'
      GROUP BY file_key 
      HAVING COUNT(*) >= 3
    `);

    if (problematicJobs.rows.length > 0) {
      for (const row of problematicJobs.rows) {
        console.log(`üö´ [WORKER-REDIS] Blacklisting file: ${row.file_key} (${row.failure_count} failures)`);
        
        await pool.query(`
          UPDATE jobs 
          SET status = 'failed', 
              error = $1, 
              updated_at = NOW()
          WHERE file_key = $2 
          AND status IN ('queued', 'processing')
        `, [
          `BLACKLISTED: File failed ${row.failure_count} times - likely corrupted/problematic`,
          row.file_key
        ]);
      }
      
      console.log(`üö´ [WORKER-REDIS] Blacklisted ${problematicJobs.rows.length} problematic files`);
    } else {
      console.log("‚úÖ [WORKER-REDIS] Nenhum job problem√°tico encontrado para blacklist");
    }
    
    const result = await pool.query(`
      UPDATE jobs 
      SET status = 'queued', updated_at = NOW(), error = 'Recovered from orphaned state by Redis worker'
      WHERE status = 'processing' 
      AND updated_at < NOW() - INTERVAL '10 minutes'
      AND error NOT LIKE '%BLACKLISTED%'
      RETURNING id, file_key
    `);

    if (result.rows.length > 0) {
      console.log(`üîÑ [WORKER-REDIS] Recuperados ${result.rows.length} jobs √≥rf√£os:`, result.rows.map(r => r.id.substring(0,8)));
    }
  } catch (err) {
    console.error("‚ùå [WORKER-REDIS] Erro ao recuperar jobs √≥rf√£os:", err);
  }
}

setInterval(recoverOrphanedJobs, 300000);
recoverOrphanedJobs();

// ---------- Graceful Shutdown ----------
process.on('SIGINT', async () => {
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üì• Recebido SIGINT, encerrando worker...`);
  try {
    await worker.close();
    console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚úÖ Worker fechado graciosamente`);
  } catch (err) {
    console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚ùå Erro ao fechar worker:`, err);
  }
  process.exit(0);
});

process.on('SIGTERM', async () => {
  console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üì• Recebido SIGTERM, encerrando worker...`);
  try {
    await worker.close();
    console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚úÖ Worker fechado graciosamente`);
  } catch (err) {
    console.error(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚ùå Erro ao fechar worker:`, err);
  }
  process.exit(0);
});

console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üöÄ Worker Redis EXCLUSIVO iniciado! PID: ${process.pid}`);
console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> ‚ö° Pronto para processar ${concurrency} jobs simult√¢neos`);
console.log(`[WORKER-REDIS][${new Date().toISOString()}] -> üéØ Aguardando jobs na fila 'audio-analyzer'...`);

// ---------- Health Check Server para Railway ----------
const healthApp = express();
const HEALTH_PORT = process.env.HEALTH_PORT || 8081;

healthApp.get('/', (req, res) => {
  res.json({ 
    status: 'Worker Redis ativo', 
    timestamp: new Date().toISOString(),
    pid: process.pid,
    concurrency: concurrency,
    redis: process.env.REDIS_URL ? 'connected' : 'disconnected'
  });
});

healthApp.get('/health', (req, res) => {
  res.json({ 
    status: 'healthy', 
    worker: 'redis-active',
    timestamp: new Date().toISOString(),
    pid: process.pid
  });
});

healthApp.listen(HEALTH_PORT, () => {
  console.log(`üè• [WORKER-REDIS] Health check server rodando na porta ${HEALTH_PORT}`);
});