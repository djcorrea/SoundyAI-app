// worker-redis.js - WORKER REDIS EXCLUSIVO (ARQUITETURA REFATORADA)
// ğŸš€ ÃšNICO RESPONSÃVEL POR PROCESSAMENTO - Legacy workers removidos

import "dotenv/config";
import { createWorker, getQueueStats } from './queue/redis.js';
import pool from './db.js';
import AWS from "aws-sdk";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";

// ---------- Importar pipeline completo ----------
let processAudioComplete = null;

try {
  const imported = await import("./api/audio/pipeline-complete.js");
  processAudioComplete = imported.processAudioComplete;
  console.log("âœ… [WORKER-REDIS] Pipeline completo carregado com sucesso!");
} catch (err) {
  console.error("âŒ [WORKER-REDIS] CRÃTICO: Falha ao carregar pipeline:", err.message);
  process.exit(1);
}

// ---------- Resolver __dirname ----------
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// ---------- Verificar conexÃ£o Postgres via Singleton ----------
let pgConnected = false;
try {
  // Testar conexÃ£o com o pool Singleton
  const testResult = await pool.query('SELECT NOW()');
  pgConnected = true;
  console.log("âœ… [WORKER-REDIS] Conectado ao Postgres via Singleton Pool");
} catch (err) {
  console.warn("âš ï¸ [WORKER-REDIS] Postgres nÃ£o disponÃ­vel:", err.message);
  console.log("ğŸ§ª [WORKER-REDIS] Continuando em modo mock sem Postgres");
}

// ---------- ConfiguraÃ§Ã£o Backblaze ----------
console.log("ğŸ” [WORKER-REDIS] Debug B2 Config:");
console.log("   B2_KEY_ID:", process.env.B2_KEY_ID);
console.log("   B2_APP_KEY:", process.env.B2_APP_KEY?.substring(0,10) + "...");
console.log("   B2_BUCKET_NAME:", process.env.B2_BUCKET_NAME);
console.log("   B2_ENDPOINT:", process.env.B2_ENDPOINT);

const s3 = new AWS.S3({
  endpoint: process.env.B2_ENDPOINT || "https://s3.us-east-005.backblazeb2.com",
  region: "us-east-005",
  accessKeyId: process.env.B2_KEY_ID,
  secretAccessKey: process.env.B2_APP_KEY,
  signatureVersion: "v4",
});
const BUCKET_NAME = process.env.B2_BUCKET_NAME;

// ---------- Baixar arquivo do bucket ----------
async function downloadFileFromBucket(key) {
  console.log(`ğŸ” [WORKER-REDIS] Tentando baixar: ${key}`);
  console.log(`ğŸ” [WORKER-REDIS] Bucket: ${BUCKET_NAME}`);
  
  const tempDir = process.env.NODE_ENV === 'production' ? '/tmp' : path.join(__dirname, 'temp');
  await fs.promises.mkdir(tempDir, { recursive: true });
  
  const localPath = path.join(tempDir, `${Date.now()}_${path.basename(key)}`);

  return new Promise((resolve, reject) => {
    const write = fs.createWriteStream(localPath);
    const read = s3.getObject({ Bucket: BUCKET_NAME, Key: key }).createReadStream();

    // ğŸ”¥ TIMEOUT DE 2 MINUTOS - EVITA DOWNLOAD INFINITO
    const timeout = setTimeout(() => {
      write.destroy();
      read.destroy();
      reject(new Error(`Download timeout apÃ³s 2 minutos para: ${key}`));
    }, 120000);

    read.on("error", (err) => {
      clearTimeout(timeout);
      console.error(`âŒ [WORKER-REDIS] Erro no stream de leitura para ${key}:`, err.message);
      reject(err);
    });
    write.on("error", (err) => {
      clearTimeout(timeout);
      console.error(`âŒ [WORKER-REDIS] Erro no stream de escrita para ${key}:`, err.message);
      reject(err);
    });
    write.on("finish", () => {
      clearTimeout(timeout);
      console.log(`âœ… [WORKER-REDIS] Download concluÃ­do para ${key}`);
      resolve(localPath);
    });

    read.pipe(write);
  });
}

// ---------- AnÃ¡lise REAL via pipeline ----------
async function analyzeAudioWithPipeline(localFilePath, jobData) {
  const filename = path.basename(localFilePath);
  
  try {
    const fileBuffer = await fs.promises.readFile(localFilePath);
    console.log(`ğŸ“Š [WORKER-REDIS] Arquivo lido: ${fileBuffer.length} bytes`);

    const t0 = Date.now();
    
    // ğŸ”¥ TIMEOUT DE 3 MINUTOS PARA EVITAR TRAVAMENTO
    const pipelinePromise = processAudioComplete(fileBuffer, filename, {
      jobId: jobData.jobId,
      reference: jobData?.reference || null
    });
    const timeoutPromise = new Promise((_, reject) => {
      setTimeout(() => {
        reject(new Error(`Pipeline timeout apÃ³s 3 minutos para: ${filename}`));
      }, 180000);
    });

    console.log(`âš¡ [WORKER-REDIS] Iniciando processamento de ${filename}...`);
    const finalJSON = await Promise.race([pipelinePromise, timeoutPromise]);
    const totalMs = Date.now() - t0;
    
    console.log(`âœ… [WORKER-REDIS] Pipeline concluÃ­do em ${totalMs}ms`);

    finalJSON.performance = {
      ...(finalJSON.performance || {}),
      workerTotalTimeMs: totalMs,
      workerTimestamp: new Date().toISOString(),
      backendPhase: "5.1-5.4-redis",
      workerId: process.pid
    };

    finalJSON._worker = { 
      source: "pipeline_complete", 
      redis: true,
      pid: process.pid
    };

    return finalJSON;
    
  } catch (error) {
    console.error(`âŒ [WORKER-REDIS] Erro crÃ­tico no pipeline para ${filename}:`, error.message);
    
    // ğŸ”¥ RETORNO DE SEGURANÃ‡A
    return {
      status: 'error',
      error: {
        message: error.message,
        type: 'worker_pipeline_error',
        phase: 'worker_redis_processing',
        timestamp: new Date().toISOString()
      },
      score: 0,
      classification: 'Erro CrÃ­tico',
      scoringMethod: 'worker_redis_error_fallback',
      metadata: {
        fileName: filename,
        fileSize: 0,
        sampleRate: 48000,
        channels: 2,
        duration: 0,
        processedAt: new Date().toISOString(),
        engineVersion: 'worker-redis-error',
        pipelinePhase: 'error'
      },
      technicalData: {},
      warnings: [`Worker Redis error: ${error.message}`],
      buildVersion: 'worker-redis-error',
      frontendCompatible: false,
      _worker: { 
        source: "pipeline_error", 
        error: true, 
        redis: true,
        pid: process.pid
      }
    };
  }
}

// ---------- Recovery de jobs Ã³rfÃ£os (movido do index.js) ----------
async function recoverOrphanedJobs() {
  if (!pgConnected) {
    console.log(`ğŸ§ª [WORKER-REDIS] Postgres nÃ£o disponÃ­vel - pulando recovery`);
    return;
  }

  try {
    console.log("ğŸ”„ [WORKER-REDIS] Verificando jobs Ã³rfÃ£os...");
    
    // ğŸš« PRIMEIRO: Blacklist jobs problemÃ¡ticos
    console.log("ğŸš« [WORKER-REDIS] Verificando jobs problemÃ¡ticos para blacklist...");
    const problematicJobs = await pool.query(`
      SELECT file_key, COUNT(*) as failure_count, 
             ARRAY_AGG(id ORDER BY created_at DESC) as job_ids
      FROM jobs 
      WHERE error LIKE '%Recovered from orphaned state%' 
      OR error LIKE '%Pipeline timeout%'
      OR error LIKE '%FFmpeg%'
      OR error LIKE '%Memory%'
      GROUP BY file_key 
      HAVING COUNT(*) >= 3
    `);

    if (problematicJobs.rows.length > 0) {
      for (const row of problematicJobs.rows) {
        console.log(`ğŸš« [WORKER-REDIS] Blacklisting file: ${row.file_key} (${row.failure_count} failures)`);
        
        // Marcar todos os jobs relacionados como failed permanentemente
        await pool.query(`
          UPDATE jobs 
          SET status = 'failed', 
              error = $1, 
              updated_at = NOW()
          WHERE file_key = $2 
          AND status IN ('queued', 'processing')
        `, [
          `BLACKLISTED: File failed ${row.failure_count} times - likely corrupted/problematic`,
          row.file_key
        ]);
      }
      
      console.log(`ğŸš« [WORKER-REDIS] Blacklisted ${problematicJobs.rows.length} problematic files`);
    } else {
      console.log("âœ… [WORKER-REDIS] Nenhum job problemÃ¡tico encontrado para blacklist");
    }
    
    // ğŸ”„ DEPOIS: Recuperar jobs Ã³rfÃ£os restantes (mas nÃ£o blacklisted)
    const result = await pool.query(`
      UPDATE jobs 
      SET status = 'queued', updated_at = NOW(), error = 'Recovered from orphaned state by Redis worker'
      WHERE status = 'processing' 
      AND updated_at < NOW() - INTERVAL '10 minutes'
      AND error NOT LIKE '%BLACKLISTED%'
      RETURNING id, file_key
    `);

    if (result.rows.length > 0) {
      console.log(`ğŸ”„ [WORKER-REDIS] Recuperados ${result.rows.length} jobs Ã³rfÃ£os:`, result.rows.map(r => r.id.substring(0,8)));
    }
  } catch (err) {
    console.error("âŒ [WORKER-REDIS] Erro ao recuperar jobs Ã³rfÃ£os:", err);
  }
}

// ğŸ”¥ RECOVERY A CADA 5 MINUTOS - Movido do index.js
setInterval(recoverOrphanedJobs, 300000);
recoverOrphanedJobs(); // Executa na inicializaÃ§Ã£o
async function updateJobStatus(jobId, status, data = null, error = null) {
  if (!pgConnected) {
    console.log(`ğŸ§ª [WORKER-REDIS] Mock update: ${jobId} -> ${status}`);
    return;
  }

  try {
    if (status === 'processing') {
      await pool.query(
        "UPDATE jobs SET status = $1, updated_at = NOW() WHERE id = $2",
        [status, jobId]
      );
    } else if (status === 'done') {
      await pool.query(
        "UPDATE jobs SET status = $1, result = $2::jsonb, completed_at = NOW(), updated_at = NOW() WHERE id = $3",
        [status, JSON.stringify(data), jobId]
      );
    } else if (status === 'failed') {
      await pool.query(
        "UPDATE jobs SET status = $1, error = $2, updated_at = NOW() WHERE id = $3",
        [status, error, jobId]
      );
    }
    console.log(`âœ… [WORKER-REDIS] Status atualizado no Postgres: ${jobId} -> ${status}`);
  } catch (err) {
    console.error(`âŒ [WORKER-REDIS] Erro ao atualizar status no Postgres:`, err.message);
  }
}

// ---------- Processor do BullMQ ----------
async function audioProcessor(job) {
  const { jobId, fileKey, mode, fileName } = job.data;
  console.log(`ğŸš€ [WORKER-REDIS] Processando job ${job.id} (${jobId}) - ${fileKey}`);

  let localFilePath = null;

  try {
    // Atualizar status para processing
    await updateJobStatus(jobId, 'processing');

    // Download do arquivo
    localFilePath = await downloadFileFromBucket(fileKey);
    console.log(`ğŸµ [WORKER-REDIS] Arquivo pronto para anÃ¡lise: ${localFilePath}`);

    // ğŸ” VALIDAÃ‡ÃƒO BÃSICA DE ARQUIVO
    console.log(`ğŸ” [WORKER-REDIS] Validando arquivo antes do pipeline...`);
    const stats = await fs.promises.stat(localFilePath);
    const fileSizeMB = stats.size / (1024 * 1024);
    
    if (stats.size < 1000) {
      throw new Error(`File too small: ${stats.size} bytes (minimum 1KB required)`);
    }
    
    if (fileSizeMB > 100) {
      throw new Error(`File too large: ${fileSizeMB.toFixed(2)} MB (maximum 100MB allowed)`);
    }
    
    console.log(`âœ… [WORKER-REDIS] Arquivo validado (${fileSizeMB.toFixed(2)} MB)`);

    // Executar pipeline
    console.log("ğŸš€ [WORKER-REDIS] Rodando pipeline completo...");
    const analysisResult = await analyzeAudioWithPipeline(localFilePath, job.data);

    const result = {
      ok: true,
      file: fileKey,
      mode: mode,
      analyzedAt: new Date().toISOString(),
      workerId: process.pid,
      redis: true,
      ...analysisResult,
    };

    // Atualizar status para done
    await updateJobStatus(jobId, 'done', result);

    console.log(`âœ… [WORKER-REDIS] Job ${job.id} (${jobId}) concluÃ­do com sucesso`);
    return result;

  } catch (error) {
    console.error(`âŒ [WORKER-REDIS] Erro no job ${job.id} (${jobId}):`, error.message);
    
    // Atualizar status para failed
    await updateJobStatus(jobId, 'failed', null, error.message);
    
    throw error; // BullMQ vai marcar como failed automaticamente
  } finally {
    // Limpar arquivo temporÃ¡rio
    if (localFilePath) {
      try {
        await fs.promises.unlink(localFilePath);
        console.log(`ğŸ—‘ï¸ [WORKER-REDIS] Arquivo temporÃ¡rio removido: ${path.basename(localFilePath)}`);
      } catch (e) {
        console.warn("âš ï¸ [WORKER-REDIS] NÃ£o foi possÃ­vel remover arquivo temporÃ¡rio:", e?.message);
      }
    }
  }
}

// ---------- Criar Worker BullMQ ----------
const concurrency = Number(process.env.WORKER_CONCURRENCY) || 5;
console.log(`ğŸ­ [WORKER-REDIS] ğŸš€ ÃšNICO WORKER RESPONSÃVEL - ConcorrÃªncia: ${concurrency}`);
console.log(`ğŸ—ï¸ [WORKER-REDIS] Arquitetura: Redis Workers Only (Legacy worker desabilitado)`);

const worker = createWorker('audio-analyzer', audioProcessor, concurrency);

// ---------- Event Listeners OTIMIZADOS - Logs estruturados ----------
worker.on('ready', () => {
  console.log(`ğŸŸ¢ [WORKER-REDIS] ğŸš€ WORKER ÃšNICO PRONTO! PID: ${process.pid}, ConcorrÃªncia: ${concurrency}`);
  console.log(`âœ… [WORKER-REDIS] Arquitetura: Redis-only (sem conflitos legacy)`);
});

// ğŸš€ OTIMIZAÃ‡ÃƒO: Logs mais informativos para debugging
worker.on('active', (job) => {
  const { jobId, fileKey } = job.data;
  console.log(`ğŸ¯ [WORKER-REDIS] ğŸ§  PROCESSANDO: ${job.id} | JobID: ${jobId?.substring(0,8)} | File: ${fileKey?.split('/').pop()}`);
});

worker.on('completed', (job, result) => {
  const { jobId, fileKey } = job.data;
  const duration = Date.now() - job.timestamp;
  console.log(`âœ… [WORKER-REDIS] ğŸ‰ CONCLUÃDO: ${job.id} | JobID: ${jobId?.substring(0,8)} | Tempo: ${duration}ms | File: ${fileKey?.split('/').pop()}`);
});

worker.on('failed', (job, err) => {
  const { jobId, fileKey } = job.data;
  console.error(`âŒ [WORKER-REDIS] ğŸ’¥ FALHADO: ${job.id} | JobID: ${jobId?.substring(0,8)} | File: ${fileKey?.split('/').pop()} | Erro: ${err.message}`);
});

worker.on('error', (err) => {
  console.error(`ğŸš¨ [WORKER-REDIS] Erro no worker:`, err.message);
});

// ---------- Monitoramento de performance OTIMIZADO - Stats da fila ----------
setInterval(async () => {
  try {
    // ğŸ”¥ STATS SIMPLIFICADAS - Apenas contadores essenciais para reduzir requests
    const stats = await getQueueStats();
    console.log(`ğŸ“Š [WORKER-REDIS] ğŸ“ˆ FILA: ${stats.waiting} aguardando | ${stats.active} ativas | ${stats.completed} completas | ${stats.failed} falhadas | PID: ${process.pid}`);
  } catch (err) {
    console.warn('âš ï¸ [WORKER-REDIS] Erro ao obter stats da fila:', err.message);
  }
}, 180000); // ğŸš€ OTIMIZADO: A cada 3 minutos (era 30s) - 6x MENOS requests Redis

// ---------- Graceful Shutdown ----------
process.on('SIGINT', async () => {
  console.log('ğŸ“¥ [WORKER-REDIS] Recebido SIGINT, encerrando worker...');
  await worker.close();
  // O pool Singleton serÃ¡ fechado quando todos os workers terminarem
  process.exit(0);
});

process.on('SIGTERM', async () => {
  console.log('ğŸ“¥ [WORKER-REDIS] Recebido SIGTERM, encerrando worker...');
  await worker.close();
  // O pool Singleton serÃ¡ fechado quando todos os workers terminarem
  process.exit(0);
});

// Tratamento de exceÃ§Ãµes nÃ£o capturadas
process.on('uncaughtException', async (err) => {
  console.error('ğŸš¨ [WORKER-REDIS] UNCAUGHT EXCEPTION:', err.message);
  console.error('ğŸ“œ Stack:', err.stack);
  
  try {
    await worker.close();
  } catch (closeErr) {
    console.error('âŒ [WORKER-REDIS] Erro ao fechar conexÃµes:', closeErr);
  }
  
  process.exit(1);
});

process.on('unhandledRejection', (reason, promise) => {
  console.error('ğŸš¨ [WORKER-REDIS] UNHANDLED REJECTION:', reason);
  console.error('ğŸ“ Promise:', promise);
});

console.log(`ğŸš€ [WORKER-REDIS] ğŸ¯ Worker Redis EXCLUSIVO iniciado! PID: ${process.pid}`);
console.log(`ğŸ—ï¸ [WORKER-REDIS] Arquitetura: Redis Workers Only - Legacy worker desabilitado`);
console.log(`âš¡ [WORKER-REDIS] Pronto para processar ${concurrency} jobs simultÃ¢neos por worker`);